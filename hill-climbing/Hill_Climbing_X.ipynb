{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L_9FNNbX2Ir"
      },
      "source": [
        "# Hill Climbing\n",
        "\n",
        "---\n",
        "\n",
        "In this notebook, we will train hill climbing with adaptive noise scaling with OpenAI Gym's Cartpole environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOJc40dyX2Is"
      },
      "source": [
        "### 1. Import the Necessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbqWavqdX2Is"
      },
      "outputs": [],
      "source": [
        "#!pip install gymnasium\n",
        "!pip install gymnasium[classic-control]\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "seed=0\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_ipython = 'inline' in plt.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display"
      ],
      "metadata": {
        "id": "LUdsKjWCpnKL"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFo9x96X2It"
      },
      "source": [
        "### 2. Define the Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts63DiclX2It",
        "outputId": "ae827101-a124-4de8-e210-b7ccbbe51624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "observation space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "action space: Discrete(2)\n"
          ]
        }
      ],
      "source": [
        "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
        "print('observation space:', env.observation_space)\n",
        "print('action space:', env.action_space)\n",
        "\n",
        "class Policy():\n",
        "    def __init__(self, s_size=4, a_size=2):\n",
        "        self.w = 1e-4*np.random.rand(s_size, a_size)  # weights for simple linear policy: state_space x action_space\n",
        "        \n",
        "    def forward(self, state):\n",
        "        x = np.dot(state, self.w)\n",
        "        return np.exp(x)/sum(np.exp(x))\n",
        "    \n",
        "    def act(self, state):\n",
        "        probs = self.forward(state)\n",
        "        #action = np.random.choice(2, p=probs) # option 1: stochastic policy\n",
        "        action = np.argmax(probs)              # option 2: deterministic policy\n",
        "        return action"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state, info = env.reset(seed=0)\n",
        "plt.imshow(env.render())\n",
        "action = policy.act(state)\n",
        "state, reward, done, truncated, info = env.step(action)\n",
        "r = np.dot(state, policy.w)\n",
        "r == reward"
      ],
      "metadata": {
        "id": "_tGMBf7gYuKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o50d6CqOX2It"
      },
      "source": [
        "### 3. Train the Agent with Stochastic Policy Search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
        "policy = Policy()"
      ],
      "metadata": {
        "id": "6hFDOArVypRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "t2yWirJvX2Iu"
      },
      "outputs": [],
      "source": [
        "def hill_climbing(n_episodes=1000, max_t=1000, gamma=1.0, print_every=100, noise_scale=1e-2, render=False):\n",
        "    \"\"\"Implementation of hill climbing with adaptive noise scaling.\n",
        "        \n",
        "    Params\n",
        "    ======\n",
        "        n_episodes (int): maximum number of training episodes\n",
        "        max_t (int): maximum number of timesteps per episode\n",
        "        gamma (float): discount rate\n",
        "        print_every (int): how often to print average score (over last 100 episodes)\n",
        "        noise_scale (float): standard deviation of additive noise\n",
        "    \"\"\"\n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores = []\n",
        "    best_R = -np.Inf\n",
        "    best_w = policy.w\n",
        "    skip_view = 25\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        rewards = []\n",
        "        obs, info = env.reset(seed=seed)\n",
        "        img = plt.imshow(env.render())\n",
        "        for t in range(max_t):\n",
        "            action = policy.act(obs)\n",
        "            obs, reward, done, truncated, info = env.step(action)\n",
        "            rewards.append(reward)\n",
        "            if render and i_episode % skip_view == 0.:\n",
        "                img.set_data(env.render())\n",
        "                plt.axis('off')\n",
        "                display.display(plt.gcf())\n",
        "                display.clear_output(wait=True)\n",
        "            if done:\n",
        "                break \n",
        "        scores_deque.append(sum(rewards))\n",
        "        scores.append(sum(rewards))\n",
        "\n",
        "        discounts = [gamma**i for i in range(len(rewards)+1)]\n",
        "        R = sum([a*b for a,b in zip(discounts, rewards)])\n",
        "\n",
        "        if R >= best_R: # found better weights\n",
        "            best_R = R\n",
        "            best_w = policy.w\n",
        "            noise_scale = max(1e-3, noise_scale / 2)\n",
        "            policy.w += noise_scale * np.random.rand(*policy.w.shape) \n",
        "        else: # did not find better weights\n",
        "            noise_scale = min(2, noise_scale * 2)\n",
        "            policy.w = best_w + noise_scale * np.random.rand(*policy.w.shape)\n",
        "\n",
        "        if i_episode % print_every == 0:\n",
        "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
        "        if np.mean(scores_deque)>=195.0:\n",
        "            print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
        "            policy.w = best_w\n",
        "            break\n",
        "        \n",
        "    return scores\n",
        "            \n",
        "#scores = hill_climbing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#policy = Policy()\n",
        "scores = hill_climbing(n_episodes=500, max_t=500, gamma=0.9995, print_every=50, noise_scale=1e-2, render=False)"
      ],
      "metadata": {
        "id": "dg9QmnuidLVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydPwlXHX2Iu"
      },
      "source": [
        "### 4. Plot the Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNRXzB0gX2Iu"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(1, len(scores)+1), scores)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYD2H7nmX2Iu"
      },
      "source": [
        "### 5. Watch a Smart Agent!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "polly=policy#Policy()\n",
        "#for i in range(50):\n",
        "state, info = env.reset(seed=seed)\n",
        "img = plt.imshow(env.render())#[0])    \n",
        "for j in range(500):\n",
        "    action = polly.act(state)\n",
        "    state, reward, done, _, info = env.step(action)\n",
        "    img.set_data(env.render())#[0]) \n",
        "    plt.axis('off')\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    if done:\n",
        "        break "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "4oSM3f8Vp9yS",
        "outputId": "ebc32887-24f7-4fa3-bd10-4069b073132e"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}