{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b058ADVF-G_"
   },
   "source": [
    "# Deep Deterministic Policy Gradients (DDPG)\n",
    "---\n",
    "In this notebook, we train DDPG with OpenAI Gym's BipedalWalker-v2 environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OotjxPANF-HB"
   },
   "outputs": [],
   "source": [
    "!pip install gymnasium[box2d]\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "#from google.colab import files\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from ddpg_agent_bip_X import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!nvcc --version\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L21oAff8F-HC"
   },
   "source": [
    "### 2. Instantiate the Environment and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1-5W70xziVv"
   },
   "outputs": [],
   "source": [
    "#gymnasium/envs/box2d/bipedal_walker.py\n",
    "#gym.pprint_registry()\n",
    "#gym.spec(\"BipedalWalker-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BVpbenjF-HC",
    "outputId": "482ba9be-1c04-4ece-bf66-cc2497cf9bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 4\n"
     ]
    }
   ],
   "source": [
    "from ddpg_agent_bip_X import Agent\n",
    "\n",
    "env = gym.make('BipedalWalker-v3', render_mode=\"rgb_array\")\n",
    "seed=10\n",
    "state_size=env.observation_space.shape[0]\n",
    "action_size=env.action_space.shape[0]\n",
    "agent = Agent(state_size=state_size, action_size=action_size, random_seed=seed)\n",
    "print(state_size, action_size)\n",
    "\n",
    "#agent.actor_local.load_state_dict(torch.load('./data/highscore_actor_bip.pth'), map_location=torch.device('cpu'))\n",
    "#agent.critic_local.load_state_dict(torch.load('./data/highscore_critic_bip.pth'), map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zRWlT6LhF-HD"
   },
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=2000, max_t=1600, max_score=-10000.):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    #max_score = -10000 #-np.Inf\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state, _ = env.reset(seed=seed)\n",
    "        agent.reset()\n",
    "        score = 0\n",
    "        \n",
    "        for step in range(max_t):\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, trun, _ = env.step(action)\n",
    "            if reward==-100.:\n",
    "                prob = step/1600\n",
    "                reward = -8*prob\n",
    "            else:\n",
    "                prob = (1.+reward+(1600-step)/1600)\n",
    "                if reward>=0.: \n",
    "                    reward = prob\n",
    "                    prob = 8*prob\n",
    "                else:\n",
    "                    reward = prob\n",
    "                    prob = 4*prob-2\n",
    "\n",
    "            agent.step(state, action, reward, next_state, done or trun, prob)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done or trun or reward==-3.0:\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if score >= max_score + int(np.round(np.abs(0.2*max_score))):\n",
    "            torch.save(agent.actor_local.state_dict(), './data/highscore_actor_bip.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), './data/highscore_critic_bip.pth')\n",
    "            print('\\rEpisode {}\\tNEW HIGH SCORE! {:.2f}'.format(i_episode, score))\n",
    "            max_score = score           \n",
    "        if i_episode % 100 == 0:\n",
    "            torch.save(agent.actor_local.state_dict(), './data/checkpoint_actor_bip.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), './data/checkpoint_critic_bip.pth')\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tHigh Score: {:.2f}'.format(i_episode, np.mean(scores_deque), max_score))   \n",
    "    return scores, max_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVzlW7asF-HD"
   },
   "source": [
    "### 3. Train the Agent with DDPG\n",
    "\n",
    "Run the code cell below to train the agent from scratch.  Alternatively, you can skip to the next code cell to load the pre-trained weights from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_agent_bip_X import BATCH_SIZE\n",
    "#agent = Agent(state_size=state_size, action_size=action_size, random_seed=seed)\n",
    "high_score=-1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuP-YSFI8US5"
   },
   "outputs": [],
   "source": [
    "scores, high_score = ddpg(n_episodes=500, max_score=high_score)#-1000000)\n",
    "#scores += ores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13qXAsmAqx0K",
    "outputId": "faf9971d-6297-4b48-a507-6073ceeb1021"
   },
   "outputs": [],
   "source": [
    "#scores = ddpg(n_episodes=2000, max_t=800)\n",
    "# ~23 min for N=1000 T=500\n",
    "#scores = []; new_scores = []; high_score = -10000.\n",
    "n_episodes=[400, 200, 200, 400]#, 300, 300, 600,  300, 300, 600]\n",
    "max_t=     [200, 400, 1200, 1600]#, 200, 600, 1200, 200, 400, 800]\n",
    "#n_episodes=[ne//4 for ne in n_episodes]\n",
    "\n",
    "for ne, mt in zip(n_episodes, max_t):\n",
    "    print('\\r### Episodes: {}\\tTime Limit: {:.2f} ###'.format(ne,mt))\n",
    "    new_scores, high_score = ddpg(n_episodes=ne, max_score=high_score)\n",
    "    scores += new_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ne, mt in zip(n_episodes, max_t):\n",
    "    print('\\r### Episodes: {}\\tTime Limit: {:.2f} ###'.format(ne,mt))\n",
    "    new_scores, high_score = ddpg(n_episodes=ne, max_score=high_score)\n",
    "    scores += new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "hlLJLwroNdzq",
    "outputId": "39f43620-1352-436a-d98b-6c55a2833219"
   },
   "outputs": [],
   "source": [
    "torch.save(agent.actor_local.state_dict(), './data/checkpoint_actor_bip.pth')\n",
    "torch.save(agent.critic_local.state_dict(), './data/checkpoint_critic_bip.pth')\n",
    "#files.download('checkpoint_criticA_bip.pth')\n",
    "#files.download('checkpoint_actorA_bip.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "Bu-bNkXYWwJL",
    "outputId": "0aa63957-cb4f-4f9a-9545-d2ef5b295011"
   },
   "outputs": [],
   "source": [
    "### Scores plot\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, )\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = random.choices(agent.memory.memory, k=BATCH_SIZE, cum_weights=agent.memory.priority_weights)\n",
    "estates = [e.state for e in experiences if e is not None]\n",
    "eactions = [e.action for e in experiences if e is not None]\n",
    "erewards = [e.reward for e in experiences if e is not None]\n",
    "enext_states = [e.next_state for e in experiences if e is not None]\n",
    "edones = [e.done for e in experiences if e is not None]\n",
    "\n",
    "emu = np.mean(np.asarray(estates + enext_states), axis=0)\n",
    "esig = np.std(np.asarray(estates + enext_states), axis=0) + 1e-3\n",
    "\n",
    "#if len(agent.memory.memory)>200:\n",
    "estates = (np.asarray(estates)-emu) / esig\n",
    "enext_states = (np.asarray(enext_states)-emu) / esig\n",
    "emu, esig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(experiences), len(agent.memory.memory), emu, esig, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Read data\n",
    "states_df = pd.read_csv('./data/states.csv', index_col=0)\n",
    "nexts_df = pd.read_csv('./data/next_states.csv', index_col=0)\n",
    "actions_df = pd.read_csv('./data/actions.csv', index_col=0)\n",
    "norm_states_df = pd.read_csv('./data/norm_states.csv', index_col=0)\n",
    "norm_nexts_df = pd.read_csv('./data/norm_next_states.csv', index_col=0)\n",
    "rewprodon_df = pd.read_csv('./data/rewprodon.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agmem = agent.memory.memory\n",
    "probs = [pw for pw in agent.memory.priority_weights if pw is not None]\n",
    "states = [e.state for e in agmem if e is not None]\n",
    "actions = [e.action for e in agmem if e is not None]\n",
    "rewards = [e.reward for e in agmem if e is not None]\n",
    "nexts = [e.next_state for e in agmem if e is not None]\n",
    "dones = [e.done for e in agmem if e is not None]\n",
    "      \n",
    "mu = np.mean(np.asarray(states + nexts), axis=0)\n",
    "sig = np.std(np.asarray(states + nexts), axis=0) + 1e-3\n",
    "norm_states = (np.asarray(states)-mu) / sig\n",
    "norm_nexts = (np.asarray(nexts)-mu) / sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_df = pd.DataFrame(states)\n",
    "norm_states_df = pd.DataFrame(norm_states)\n",
    "actions_df = pd.DataFrame(actions)\n",
    "nexts_df = pd.DataFrame(nexts)\n",
    "norm_nexts_df = pd.DataFrame(norm_nexts)\n",
    "rewprodon_df = pd.DataFrame(np.asarray([rewards,probs,dones]).T, columns=[\"rewards\",\"probs\",\"dones\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data\n",
    "states_df.to_csv('./data/states.csv')\n",
    "norm_states_df.to_csv('./data/norm_states.csv')\n",
    "actions_df.to_csv('./data/actions.csv')\n",
    "nexts_df.to_csv('./data/next_states.csv')\n",
    "norm_nexts_df.to_csv('./data/norm_next_states.csv')\n",
    "rewprodon_df.to_csv('./data/rewprodon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewprodon_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts_hist = nexts_df.hist(figsize=(12,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_hist = states_df.hist(figsize=(12,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_states_hist = norm_states_df.hist(figsize=(12,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_hist = actions_df.hist(figsize=(12,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewprodon_hist = rewprodon_df.hist(figsize=(12,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(rewards)+1), rewards)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Step #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewards</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.120621</td>\n",
       "      <td>1.758758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.106384</td>\n",
       "      <td>1.787232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.176796</td>\n",
       "      <td>1.646407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.249274</td>\n",
       "      <td>1.501451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.302058</td>\n",
       "      <td>1.395884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.363889</td>\n",
       "      <td>1.272223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.442580</td>\n",
       "      <td>1.114841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.486385</td>\n",
       "      <td>1.027231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.543145</td>\n",
       "      <td>0.913710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.574304</td>\n",
       "      <td>0.851391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.606848</td>\n",
       "      <td>0.786304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.503692</td>\n",
       "      <td>0.992617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.562992</td>\n",
       "      <td>0.874017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.539267</td>\n",
       "      <td>0.921466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.399836</td>\n",
       "      <td>1.200327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.398136</td>\n",
       "      <td>1.203728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.393699</td>\n",
       "      <td>1.212603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.357754</td>\n",
       "      <td>1.284491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.355739</td>\n",
       "      <td>1.288522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.353026</td>\n",
       "      <td>1.293948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.358395</td>\n",
       "      <td>1.283210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.361364</td>\n",
       "      <td>1.277272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.360843</td>\n",
       "      <td>1.278313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.362462</td>\n",
       "      <td>1.275076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.364743</td>\n",
       "      <td>1.270514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.360898</td>\n",
       "      <td>1.278204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.356299</td>\n",
       "      <td>1.287403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.361993</td>\n",
       "      <td>1.276013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.368217</td>\n",
       "      <td>1.263565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.374395</td>\n",
       "      <td>1.251210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141692</th>\n",
       "      <td>-0.339606</td>\n",
       "      <td>1.320788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141693</th>\n",
       "      <td>-0.348145</td>\n",
       "      <td>1.303710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141694</th>\n",
       "      <td>-0.342224</td>\n",
       "      <td>1.315552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141695</th>\n",
       "      <td>-0.343076</td>\n",
       "      <td>1.313848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141696</th>\n",
       "      <td>-0.348432</td>\n",
       "      <td>1.303136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141697</th>\n",
       "      <td>-0.342713</td>\n",
       "      <td>1.314575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141698</th>\n",
       "      <td>-0.316059</td>\n",
       "      <td>1.367881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141699</th>\n",
       "      <td>-0.327715</td>\n",
       "      <td>1.344570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141700</th>\n",
       "      <td>-0.317336</td>\n",
       "      <td>1.365328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141701</th>\n",
       "      <td>-0.300323</td>\n",
       "      <td>1.399355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141702</th>\n",
       "      <td>-0.287457</td>\n",
       "      <td>1.425086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141703</th>\n",
       "      <td>-0.280664</td>\n",
       "      <td>1.438672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141704</th>\n",
       "      <td>-0.280999</td>\n",
       "      <td>1.438003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141705</th>\n",
       "      <td>-0.276562</td>\n",
       "      <td>1.446876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141706</th>\n",
       "      <td>-0.274676</td>\n",
       "      <td>1.450647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141707</th>\n",
       "      <td>-0.280871</td>\n",
       "      <td>1.438259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141708</th>\n",
       "      <td>-0.287082</td>\n",
       "      <td>1.425837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141709</th>\n",
       "      <td>-0.295806</td>\n",
       "      <td>1.408387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141710</th>\n",
       "      <td>-0.309163</td>\n",
       "      <td>1.381674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141711</th>\n",
       "      <td>-0.314771</td>\n",
       "      <td>1.370458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141712</th>\n",
       "      <td>-0.327054</td>\n",
       "      <td>1.345891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141713</th>\n",
       "      <td>-0.326761</td>\n",
       "      <td>1.346478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141714</th>\n",
       "      <td>-0.282624</td>\n",
       "      <td>1.434751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141715</th>\n",
       "      <td>-0.278484</td>\n",
       "      <td>1.443033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141716</th>\n",
       "      <td>-0.273422</td>\n",
       "      <td>1.453157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141717</th>\n",
       "      <td>-0.260141</td>\n",
       "      <td>1.479717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141718</th>\n",
       "      <td>-0.252998</td>\n",
       "      <td>1.494004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141719</th>\n",
       "      <td>-0.243402</td>\n",
       "      <td>1.513196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141720</th>\n",
       "      <td>-0.231874</td>\n",
       "      <td>1.536252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141721</th>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141722 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rewards     probs\n",
       "0      -0.120621  1.758758\n",
       "1      -0.106384  1.787232\n",
       "2      -0.176796  1.646407\n",
       "3      -0.249274  1.501451\n",
       "4      -0.302058  1.395884\n",
       "5      -0.363889  1.272223\n",
       "6      -0.442580  1.114841\n",
       "7      -0.486385  1.027231\n",
       "8      -0.543145  0.913710\n",
       "9      -0.574304  0.851391\n",
       "10     -0.606848  0.786304\n",
       "11     -0.503692  0.992617\n",
       "12     -0.562992  0.874017\n",
       "13     -0.539267  0.921466\n",
       "14     -0.399836  1.200327\n",
       "15     -0.398136  1.203728\n",
       "16     -0.393699  1.212603\n",
       "17     -0.357754  1.284491\n",
       "18     -0.355739  1.288522\n",
       "19     -0.353026  1.293948\n",
       "20     -0.358395  1.283210\n",
       "21     -0.361364  1.277272\n",
       "22     -0.360843  1.278313\n",
       "23     -0.362462  1.275076\n",
       "24     -0.364743  1.270514\n",
       "25     -0.360898  1.278204\n",
       "26     -0.356299  1.287403\n",
       "27     -0.361993  1.276013\n",
       "28     -0.368217  1.263565\n",
       "29     -0.374395  1.251210\n",
       "...          ...       ...\n",
       "141692 -0.339606  1.320788\n",
       "141693 -0.348145  1.303710\n",
       "141694 -0.342224  1.315552\n",
       "141695 -0.343076  1.313848\n",
       "141696 -0.348432  1.303136\n",
       "141697 -0.342713  1.314575\n",
       "141698 -0.316059  1.367881\n",
       "141699 -0.327715  1.344570\n",
       "141700 -0.317336  1.365328\n",
       "141701 -0.300323  1.399355\n",
       "141702 -0.287457  1.425086\n",
       "141703 -0.280664  1.438672\n",
       "141704 -0.280999  1.438003\n",
       "141705 -0.276562  1.446876\n",
       "141706 -0.274676  1.450647\n",
       "141707 -0.280871  1.438259\n",
       "141708 -0.287082  1.425837\n",
       "141709 -0.295806  1.408387\n",
       "141710 -0.309163  1.381674\n",
       "141711 -0.314771  1.370458\n",
       "141712 -0.327054  1.345891\n",
       "141713 -0.326761  1.346478\n",
       "141714 -0.282624  1.434751\n",
       "141715 -0.278484  1.443033\n",
       "141716 -0.273422  1.453157\n",
       "141717 -0.260141  1.479717\n",
       "141718 -0.252998  1.494004\n",
       "141719 -0.243402  1.513196\n",
       "141720 -0.231874  1.536252\n",
       "141721 -3.000000  0.100000\n",
       "\n",
       "[141722 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewprodon_df[['rewards','probs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 24]), torch.Size([32, 24]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch.nn as nn\n",
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm1d(state_size)\n",
    "# Without Learnable Parameters\n",
    "#m = nn.BatchNorm1d(100, affine=False)\n",
    "batch_size = 32\n",
    "input = torch.randn(batch_size, state_size)\n",
    "output = m(input)\n",
    "input.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1184,  0.0000, -0.0000, -0.0000, -0.8079, -0.0000,  0.9158,\n",
       "          0.0000,  1.0000,  1.1192,  0.0000,  0.9319,  0.0000,  1.0000,\n",
       "          0.2929,  0.2962,  0.3066,  0.3253,  0.3549,  0.4003,  0.4712,\n",
       "          0.5886,  0.8083,  1.0000],\n",
       "        [-0.1236, -0.0000,  0.0000, -0.0000, -0.8136, -0.0000,  0.9166,\n",
       "          0.0000,  1.0000,  1.1346,  0.0000,  0.9309,  0.0000,  1.0000,\n",
       "          0.2894,  0.2927,  0.3029,  0.3214,  0.3506,  0.3955,  0.4655,\n",
       "          0.5816,  0.7986,  1.0000],\n",
       "        [-0.1228,  0.0000, -0.0000, -0.0000, -0.8070, -0.0000,  0.9001,\n",
       "          0.0000,  1.0000,  1.1346,  0.0000,  0.9320,  0.0000,  1.0000,\n",
       "          0.2887,  0.2920,  0.3022,  0.3206,  0.3498,  0.3945,  0.4644,\n",
       "          0.5802,  0.7967,  1.0000],\n",
       "        [ 0.3165, -0.0207,  0.1434, -0.0353, -0.8344,  0.0000,  0.9017,\n",
       "          0.0000,  0.0000, -0.8098, -0.0000,  0.9027, -0.0000,  1.0000,\n",
       "          0.4357,  0.4407,  0.4561,  0.4839,  0.5279,  0.5955,  0.7010,\n",
       "          0.8757,  1.0000,  1.0000],\n",
       "        [ 0.0077, -0.0000,  0.0000, -0.0000, -0.8231, -0.0000,  0.9253,\n",
       "          0.0000,  1.0000,  1.1348,  0.0000, -0.6342,  0.0000,  1.0000,\n",
       "          0.3321,  0.3358,  0.3476,  0.3688,  0.4023,  0.4538,  0.5342,\n",
       "          0.6674,  0.9221,  1.0000],\n",
       "        [ 0.2792, -0.0478,  0.1420, -0.0396, -0.8024, -0.0000,  0.9349,\n",
       "          0.0000,  1.0000, -0.8182,  0.0000, -0.6251,  0.0000,  0.0000,\n",
       "          0.4137,  0.4184,  0.4331,  0.4595,  0.5013,  0.5655,  0.6656,\n",
       "          0.8315,  1.0000,  1.0000],\n",
       "        [-0.1274, -0.0000,  0.0000, -0.0000, -0.8156,  0.0000,  0.9302,\n",
       "          0.0000,  1.0000,  1.1347,  0.0000,  0.9329, -0.0000,  1.0000,\n",
       "          0.2901,  0.2934,  0.3036,  0.3221,  0.3514,  0.3964,  0.4666,\n",
       "          0.5830,  0.8005,  1.0000],\n",
       "        [-0.1228,  0.0000,  0.0000, -0.0000, -0.8070, -0.0000,  0.9001,\n",
       "          0.0000,  1.0000,  1.1346,  0.0000,  0.9320,  0.0000,  1.0000,\n",
       "          0.2887,  0.2920,  0.3022,  0.3206,  0.3498,  0.3945,  0.4644,\n",
       "          0.5802,  0.7967,  1.0000],\n",
       "        [-0.1130,  0.0000,  0.0000,  0.0000, -0.8273,  0.0000,  0.9067,\n",
       "          0.0000,  1.0000,  1.1344,  0.0000,  0.9292,  0.0000,  1.0000,\n",
       "          0.2862,  0.2895,  0.2996,  0.3178,  0.3468,  0.3911,  0.4604,\n",
       "          0.5752,  0.7898,  1.0000],\n",
       "        [-0.1296,  0.0000, -0.0000,  0.0000, -0.8016, -0.0000,  0.9212,\n",
       "          0.0000,  1.0000,  1.1342,  0.0000,  0.9284,  0.0000,  1.0000,\n",
       "          0.2925,  0.2959,  0.3062,  0.3249,  0.3544,  0.3998,  0.4706,\n",
       "          0.5879,  0.8073,  1.0000],\n",
       "        [-0.1341,  0.0000, -0.0000, -0.0000, -0.8034,  0.0000,  0.9335,\n",
       "          0.0000,  1.0000,  1.1348, -0.0000,  0.9341, -0.0000,  1.0000,\n",
       "          0.2922,  0.2955,  0.3058,  0.3245,  0.3540,  0.3993,  0.4700,\n",
       "          0.5872,  0.8069,  1.0000],\n",
       "        [-0.0247, -0.0551,  0.2916, -0.1864, -0.8096,  0.0001,  0.9123,\n",
       "          0.0000,  1.0000, -0.8260, -0.0000, -0.6210, -0.0000,  0.0000,\n",
       "          0.3247,  0.3284,  0.3399,  0.3606,  0.3935,  0.4438,  0.5224,\n",
       "          0.6526,  0.8998,  1.0000],\n",
       "        [-0.1133,  0.0000,  0.0000,  0.0000, -0.8125,  0.0000,  0.9100,\n",
       "          0.0000,  1.0000,  1.1210,  0.0000,  0.9215,  0.0000,  1.0000,\n",
       "          0.2919,  0.2952,  0.3056,  0.3242,  0.3537,  0.3989,  0.4696,\n",
       "          0.5867,  0.8056,  1.0000],\n",
       "        [ 0.0077, -0.0000,  0.0000,  0.0000, -0.8231,  0.0000,  0.9253,\n",
       "          0.0000,  1.0000,  1.1348, -0.0000, -0.6342, -0.0000,  1.0000,\n",
       "          0.3321,  0.3358,  0.3476,  0.3688,  0.4023,  0.4538,  0.5342,\n",
       "          0.6674,  0.9221,  1.0000],\n",
       "        [ 0.0105, -0.0000,  0.0000, -0.0000, -0.8131,  0.0000,  0.9078,\n",
       "          0.0000,  1.0000,  1.1338, -0.0000, -0.6114, -0.0000,  1.0000,\n",
       "          0.3333,  0.3371,  0.3489,  0.3702,  0.4039,  0.4556,  0.5363,\n",
       "          0.6699,  0.9276,  1.0000],\n",
       "        [ 0.0030,  0.0000, -0.0000, -0.0000, -0.8119,  0.0000,  0.9168,\n",
       "          0.0000,  1.0000,  1.1345, -0.0000, -0.6323, -0.0000,  1.0000,\n",
       "          0.3328,  0.3366,  0.3483,  0.3696,  0.4032,  0.4548,  0.5353,\n",
       "          0.6688,  0.9239,  1.0000],\n",
       "        [-0.1233, -0.0000,  0.0000, -0.0000, -0.8123,  0.0000,  0.9111,\n",
       "          0.0000,  1.0000,  1.1346, -0.0000,  0.9335, -0.0000,  1.0000,\n",
       "          0.2886,  0.2919,  0.3021,  0.3205,  0.3497,  0.3944,  0.4642,\n",
       "          0.5800,  0.7964,  1.0000],\n",
       "        [-0.1277,  0.0000, -0.0000,  0.0000, -0.8015, -0.0000,  0.9137,\n",
       "          0.0000,  1.0000,  1.1339,  0.0000,  0.9276,  0.0000,  1.0000,\n",
       "          0.2913,  0.2946,  0.3050,  0.3236,  0.3530,  0.3982,  0.4687,\n",
       "          0.5855,  0.8040,  1.0000],\n",
       "        [ 0.0126, -0.0000,  0.0000, -0.0000, -0.8235,  0.0000,  0.9163,\n",
       "          0.0000,  1.0000,  1.1341,  0.0000, -0.6289, -0.0000,  1.0000,\n",
       "          0.3320,  0.3358,  0.3476,  0.3688,  0.4023,  0.4538,  0.5342,\n",
       "          0.6673,  0.9194,  1.0000],\n",
       "        [ 0.4075, -0.0131,  0.0943, -0.0206, -0.7962,  0.1088,  0.9034,\n",
       "          0.0000,  0.0000, -0.8276,  0.0000,  0.9018, -0.0035,  1.0000,\n",
       "          0.4444,  0.4494,  0.4652,  0.4935,  0.5384,  0.6073,  0.7149,\n",
       "          0.8931,  1.0000,  1.0000],\n",
       "        [-0.1213, -0.0000,  0.0000,  0.0000, -0.8144,  0.0000,  0.9134,\n",
       "          0.0000,  1.0000,  1.1340,  0.0000,  0.9284,  0.0000,  1.0000,\n",
       "          0.2890,  0.2922,  0.3025,  0.3209,  0.3501,  0.3949,  0.4649,\n",
       "          0.5808,  0.7975,  1.0000],\n",
       "        [-0.8999,  0.0086, -0.0630, -0.0004,  1.1326,  0.0001,  0.9270,\n",
       "          0.0000,  1.0000,  1.1064, -0.0000,  0.9052, -0.0000,  0.0000,\n",
       "          0.4565,  0.4617,  0.4779,  0.5070,  0.5531,  0.6239,  0.7344,\n",
       "          0.9175,  1.0000,  1.0000],\n",
       "        [-0.1224,  0.0000,  0.0000,  0.0000, -0.8101,  0.0000,  0.9014,\n",
       "          0.0000,  1.0000,  1.1347,  0.0000,  0.9329,  0.0000,  1.0000,\n",
       "          0.2884,  0.2916,  0.3018,  0.3202,  0.3494,  0.3941,  0.4639,\n",
       "          0.5795,  0.7958,  1.0000],\n",
       "        [-0.1112, -0.0000, -0.0000, -0.0000, -0.8318,  0.0000,  0.9082,\n",
       "          0.0000,  1.0000,  1.1339,  0.0000,  0.9279, -0.0000,  1.0000,\n",
       "          0.2856,  0.2888,  0.2989,  0.3171,  0.3460,  0.3903,  0.4594,\n",
       "          0.5739,  0.7880,  1.0000],\n",
       "        [-0.1235,  0.0000,  0.0000, -0.0000, -0.8062, -0.0000,  0.9101,\n",
       "          0.0000,  1.0000,  1.1333,  0.0000,  0.9252,  0.0000,  1.0000,\n",
       "          0.2905,  0.2938,  0.3041,  0.3226,  0.3520,  0.3970,  0.4673,\n",
       "          0.5838,  0.8016,  1.0000],\n",
       "        [-0.1242,  0.0000,  0.0000,  0.0000, -0.8206,  0.0000,  0.9289,\n",
       "          0.0000,  1.0000,  1.1349, -0.0000,  0.9349, -0.0000,  1.0000,\n",
       "          0.2886,  0.2919,  0.3021,  0.3205,  0.3496,  0.3944,  0.4642,\n",
       "          0.5800,  0.7964,  1.0000],\n",
       "        [ 0.0137, -0.0549,  0.1492, -0.1694, -0.8338, -0.0000,  0.9321,\n",
       "          0.0000,  0.0000,  1.1332,  0.0000,  0.9349,  0.0000,  0.0000,\n",
       "          0.3516,  0.3556,  0.3680,  0.3904,  0.4260,  0.4805,  0.5656,\n",
       "          0.7066,  0.9797,  1.0000],\n",
       "        [-0.1343,  0.0000, -0.0000, -0.0000, -0.8041, -0.0000,  0.9335,\n",
       "          0.0000,  1.0000,  1.1348,  0.0000,  0.9338,  0.0000,  1.0000,\n",
       "          0.2923,  0.2956,  0.3060,  0.3246,  0.3541,  0.3995,  0.4702,\n",
       "          0.5874,  0.8072,  1.0000],\n",
       "        [-0.1277,  0.0000,  0.0000,  0.0000, -0.8015,  0.0000,  0.9137,\n",
       "          0.0000,  1.0000,  1.1339,  0.0000,  0.9276,  0.0000,  1.0000,\n",
       "          0.2913,  0.2946,  0.3050,  0.3236,  0.3530,  0.3982,  0.4687,\n",
       "          0.5855,  0.8040,  1.0000],\n",
       "        [ 0.0076, -0.0000,  0.0000, -0.0000, -0.8126,  0.0000,  0.9044,\n",
       "          0.0000,  1.0000,  1.1331, -0.0000, -0.6348, -0.0000,  1.0000,\n",
       "          0.3321,  0.3359,  0.3477,  0.3689,  0.4024,  0.4539,  0.5343,\n",
       "          0.6675,  0.9253,  1.0000],\n",
       "        [-0.1250, -0.0000,  0.0000, -0.0000, -0.8107, -0.0000,  0.9209,\n",
       "          0.0000,  1.0000,  1.1339,  0.0000,  0.9278,  0.0000,  0.0000,\n",
       "          0.2904,  0.2937,  0.3040,  0.3225,  0.3518,  0.3969,  0.4671,\n",
       "          0.5836,  0.8013,  1.0000],\n",
       "        [-0.1132,  0.0000,  0.0000,  0.0000, -0.8274,  0.0000,  0.9060,\n",
       "          0.0000,  1.0000,  1.1343,  0.0000,  0.9283,  0.0000,  1.0000,\n",
       "          0.2865,  0.2898,  0.2999,  0.3182,  0.3472,  0.3916,  0.4610,\n",
       "          0.5759,  0.7908,  1.0000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#states = \n",
    "samps = np.asarray(states_df.sample(n=32, replace=False, weights=rewprodon_df['probs']))\n",
    "torch.from_numpy(samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d55f5b47a388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbtchnrm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbtchnrm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.shape#, btchnrm(s).shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#m(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.batch_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1193\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "btchnrm = nn.BatchNorm1d(state_size)\n",
    "s = torch.from_numpy(np.asarray(sampstates).astype(np.float))\n",
    "btchnrm(s)#.shape#, btchnrm(s).shape\n",
    "#m(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq-Y0saUF-HE"
   },
   "source": [
    "### 4. Watch a Smart Agent!\n",
    "\n",
    "In the next code cell, you will load the trained weights from file to watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMEOLXYbVIOz",
    "outputId": "66a2f4fb-6b6a-475f-f7da-b3a6c20e345a"
   },
   "outputs": [],
   "source": [
    "agent.actor_local.load_state_dict(torch.load('./data/highscore_actor_bip.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('./data/highscore_critic_bip.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "q2nu72h6kfSO",
    "outputId": "452218bd-0ec9-4097-8066-238a3c470aa0"
   },
   "outputs": [],
   "source": [
    "#### Record Frames from Episodes\n",
    "episodes = []\n",
    "n_episodes = 3\n",
    "for ep in range(n_episodes):\n",
    "    epiframes = []\n",
    "    epirew = 0.\n",
    "    max_t = 1600\n",
    "    state, info = env.reset(seed=seed)\n",
    "    for t in range(max_t):\n",
    "        frame = env.render()\n",
    "        action = agent.act(state)\n",
    "        state, steprew, done, trun, info = env.step(action)\n",
    "        if steprew<=-3.: steprew = -3.\n",
    "        epirew += steprew\n",
    "        epiframes.append([t+1, np.round(steprew,3), np.round(epirew,3), frame])\n",
    "        if done or trun:\n",
    "            break \n",
    "    episodes.append(epiframes)\n",
    "    print(\"Total episode \", ep+1,\" rewards: \", np.round(epirew,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cozryFUIQSMC",
    "outputId": "c2f09146-ed33-4d70-8fe7-048e946f6b46"
   },
   "outputs": [],
   "source": [
    "fig = plt.Figure(figsize=(12,10))\n",
    "plt.axis('off')\n",
    "for epiframes in episodes:\n",
    "    img = plt.imshow(epiframes[0][3])\n",
    "    for step, steprew, epirew, frame in epiframes[1:]:\n",
    "        img.set_data(frame) \n",
    "        title = \"Step: \"+str(step)+\"  Step Reward: \"+str(steprew)+\"   Episode Reward: \"+str(epirew)\n",
    "        plt.title(title)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epiframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHxu9O8aaw6W"
   },
   "outputs": [],
   "source": [
    "#### Get data\n",
    "rewards = []\n",
    "final_rewards = []\n",
    "steps = []\n",
    "actions = []\n",
    "tries = 100\n",
    "max_t = 400\n",
    "for i in range(tries):\n",
    "    step_count = 0\n",
    "    reward_sum = 0\n",
    "    state, info = env.reset(seed=seed)\n",
    "    for j in range(max_t):\n",
    "        action = agent.act(state)\n",
    "        actions += [action]\n",
    "        state, reward, done, trun, info = env.step(action)\n",
    "        if done or trun:\n",
    "            final_rewards += [reward]\n",
    "            break \n",
    "        else:\n",
    "            final_rewards += [0]\n",
    "            reward_sum += reward\n",
    "            step_count += 1\n",
    "    steps += [step_count]\n",
    "    rewards += [reward_sum]\n",
    "actions = np.asarray(actions)\n",
    "data = np.asarray([(int(s),int(r),int(f)) for s,r,f in zip(steps, np.round(rewards), final_rewards)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdq0pwI0afFC",
    "outputId": "e4211ec9-a7de-4f66-c715-416265f85a35"
   },
   "outputs": [],
   "source": [
    "#data = np.asarray([(int(s),int(r),int(f)) for s,r,f in zip(steps, np.round(rewards), final_rewards)])\n",
    "[d for d in data if d[1]<0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGIWhy0IRm2Q",
    "outputId": "f7b769d2-554a-4c2b-9245-7a9ed5eca1d3"
   },
   "outputs": [],
   "source": [
    "actions[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgwknWtKJiiz",
    "outputId": "5d5884a7-323f-4acf-862e-615ea47785a0"
   },
   "outputs": [],
   "source": [
    "np.mean(data[:,1]/data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1h83Jwk2NRtt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQLQdLKzgFaY"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(rewards)+1), rewards)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()\n",
    "print(\"Total Rewards[:-1]\", sum(rewards), \"Average Reward:\", np.mean(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3ihoD0dWi9L"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(rewards[:-1])+1), rewards[:-1])\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Step #')\n",
    "plt.show()\n",
    "print(\"Total Rewards[:-1]\", sum(rewards[:-1]), \"Final Reward:\", rewards[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1wigUfbF-HF"
   },
   "source": [
    "# 5. Explore\n",
    "\n",
    "In this exercise, we have provided a sample DDPG agent and demonstrated how to use it to solve an OpenAI Gym environment.  To continue your learning, you are encouraged to complete any (or all!) of the following tasks:\n",
    "- **Amend the various hyperparameters and network architecture to see if you can get your agent to solve the environment faster than this benchmark implementation.**  Once you build intuition for the hyperparameters that work well with this environment, try solving a different OpenAI Gym task!\n",
    "- Write your own DDPG implementation.  Use this code as reference only when needed -- try as much as you can to write your own algorithm from scratch.\n",
    "- You may also like to implement **prioritized experience replay**, to see if it speeds learning.  \n",
    "- The current implementation adds Ornsetein-Uhlenbeck noise to the action space.  However, it has [been shown](https://blog.openai.com/better-exploration-with-parameter-noise/) that **adding noise to the parameters of the neural network policy can improve performance.  Make this change to the code, to verify it for yourself!**\n",
    "- Write a blog post explaining the intuition behind the DDPG algorithm and demonstrating how to use it to solve an RL environment of your choosing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAsuFULRviuL"
   },
   "source": [
    "## How well does DQN with Tile Coding how well does work?\n",
    "* Reuse DQN from Project 1, but use Tile Coding to turn continuous into discrete actions\n",
    "* Implement improvements on DQN from Project 1 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvUpCpQ7wXIh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
