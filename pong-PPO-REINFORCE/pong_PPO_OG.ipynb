{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nyWTPej2qkp"
   },
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lk3IydYxyZA5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[accept-rom-license] in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (4.4.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (0.0.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (1.24.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (6.0.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[accept-rom-license]) (0.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.28.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (8.1.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (0.5.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[accept-rom-license]) (3.15.0)\n",
      "Requirement already satisfied: libtorrent in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from AutoROM.accept-rom-license->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gymnasium[accept-rom-license]) (3.4)\n",
      "Requirement already satisfied: gymnasium[atari] in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (0.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (4.4.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (0.0.1)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (2.2.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (1.24.2)\n",
      "Requirement already satisfied: shimmy[atari]<1.0,>=0.1.0 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from gymnasium[atari]) (0.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium[atari]) (3.15.0)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from shimmy[atari]<1.0,>=0.1.0->gymnasium[atari]) (0.8.1)\n",
      "Requirement already satisfied: importlib-resources in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0->gymnasium[atari]) (5.12.0)\n",
      "Requirement already satisfied: progressbar in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (2.5)\n",
      "Requirement already satisfied: JSAnimation in c:\\programdata\\anaconda3\\envs\\general\\lib\\site-packages (0.1)\n",
      "using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "!pip install gymnasium[accept-rom-license]\n",
    "!pip install gymnasium[atari]\n",
    "import gymnasium as gym\n",
    "\n",
    "!pip install progressbar\n",
    "import progressbar as pb\n",
    "\n",
    "import random as rand\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "%matplotlib inline\n",
    "\n",
    "# install package for displaying animation\n",
    "!pip install JSAnimation\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device: \",device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LngBG2pgC6oD"
   },
   "outputs": [],
   "source": [
    "import pong_utils\n",
    "from parallelEnv import parallelEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qLYOyrI47L-c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pong-v0',\n",
       " 'PongDeterministic-v0',\n",
       " 'PongNoFrameskip-v0',\n",
       " 'Pong-v4',\n",
       " 'PongDeterministic-v4',\n",
       " 'PongNoFrameskip-v4',\n",
       " 'Pong-ram-v0',\n",
       " 'Pong-ramDeterministic-v0',\n",
       " 'Pong-ramNoFrameskip-v0',\n",
       " 'Pong-ram-v4',\n",
       " 'Pong-ramDeterministic-v4',\n",
       " 'Pong-ramNoFrameskip-v4',\n",
       " 'ALE/Pong-v5',\n",
       " 'ALE/Pong-ram-v5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in list(gym.envs.registry.keys()) if \"Pong\" in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bvHK4cgGyZA6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "\n",
    "env = gym.make('PongDeterministic-v4')#, render_mode='rgb_array', frameskip=1, full_action_space=False)\n",
    "#env = gym.make('Pong-v4', render_mode='rgb_array', old_step_api=True)#, obs_type='grayscale'\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py\n",
    "RIGHT=4\n",
    "LEFT=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm6O2-Uc2qks"
   },
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i1mpi_NP2qks"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# show what a preprocessed image looks like\n",
    "_, _ = env.reset()\n",
    "_, _, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _, _ = env.step(LEFT)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R07DoPK32qks"
   },
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZkrkiVQi2qks"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# set up a convolutional neural net\n",
    "# the output is the probability of moving right\n",
    "# P(left) = 1-P(right)\n",
    "class WeakPolicy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(WeakPolicy, self).__init__()\n",
    "        \n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "        \n",
    "        # 80x80 to outputsize x outputsize\n",
    "        # outputsize = (inputsize - kernel_size + stride)/stride \n",
    "        # (round up if not an integer)\n",
    "\n",
    "        # output = 20x20 here\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=4, stride=4)\n",
    "        self.size=1*20*20\n",
    "        \n",
    "        # 1 fully connected layer\n",
    "        self.fc = nn.Linear(self.size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "    ########\n",
    "    ## \n",
    "    ## Modify your neural network\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "        x = F.relu(self.conv(x))\n",
    "        # flatten the tensor\n",
    "        x = x.view(-1,self.size)\n",
    "        return self.sig(self.fc(x))\n",
    "\n",
    "# run your own policy!\n",
    "# policy=Policy().to(device)\n",
    "policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsvLD9Hg2qkt"
   },
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D2qg5Q7R_-VJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvSpec(id='PongDeterministic-v4', entry_point='shimmy.atari_env:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'max_num_frames_per_episode': 108000, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WHIsVgVwI2GR"
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FileMovieWriter as filemoviewriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5i380ASt2qkt"
   },
   "outputs": [],
   "source": [
    "#pong_utils.play(env, policy, time=100)#, preprocess=pong_utils.preprocess_single) \n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqPk0dhc2qkt"
   },
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "## Exercise 2: write your own function for training\n",
    "(what I call scalar function is the same as policy_loss up to a negative sign)\n",
    "\n",
    "### PPO\n",
    "Later on, you'll implement the PPO algorithm as well, and the scalar function is given by\n",
    "$\\frac{1}{T}\\sum^T_t \\min\\left\\{R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)},R_{t}^{\\rm future}{\\rm clip}_{\\epsilon}\\!\\left(\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}\\right)\\right\\}$\n",
    "\n",
    "the ${\\rm clip}_\\epsilon$ function is implemented in pytorch as ```torch.clamp(ratio, 1-epsilon, 1+epsilon)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tydIRxGj2qkt"
   },
   "outputs": [],
   "source": [
    "def unclipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "\n",
    "    ########\n",
    "    ## \n",
    "    ## WRITE YOUR OWN CODE HERE\n",
    "    ##\n",
    "    ########\n",
    "    \n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = pong_utils.states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+ \\\n",
    "        (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "\n",
    "    return torch.mean(beta*entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dq7DQwcP8Eym"
   },
   "outputs": [],
   "source": [
    "# clipped surrogate function\n",
    "# similar as -policy_loss for REINFORCE, but for PPO\n",
    "def clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "                      discount=0.995,\n",
    "                      epsilon=0.1, beta=0.01):\n",
    "\n",
    "    discount = discount**np.arange(len(rewards))\n",
    "    rewards = np.asarray(rewards)*discount[:,np.newaxis]\n",
    "    \n",
    "    # convert rewards to future rewards\n",
    "    rewards_future = rewards[::-1].cumsum(axis=0)[::-1]\n",
    "    \n",
    "    mean = np.mean(rewards_future, axis=1)\n",
    "    std = np.std(rewards_future, axis=1) + 1.0e-10\n",
    "\n",
    "    rewards_normalized = (rewards_future - mean[:,np.newaxis])/std[:,np.newaxis]\n",
    "    \n",
    "    # convert everything into pytorch tensors and move to gpu if available\n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float, device=device)\n",
    "    rewards = torch.tensor(rewards_normalized, dtype=torch.float, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == RIGHT, new_probs, 1.0-new_probs)\n",
    "    \n",
    "    # ratio for clipping\n",
    "    ratio = new_probs/old_probs\n",
    "\n",
    "    # clipped function\n",
    "    clip = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "    clipped_surrogate = torch.min(ratio*rewards, clip*rewards)\n",
    "\n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+ \\\n",
    "        (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "\n",
    "    \n",
    "    # this returns an average of all the entries of the tensor\n",
    "    # effective computing L_sur^clip / T\n",
    "    # averaged over time-step and number of trajectories\n",
    "    # this is desirable because we have normalized our rewards\n",
    "    return torch.mean(clipped_surrogate + beta*entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3zQsz-W2qku"
   },
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "H28z7Px92qku",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   0% |                                          | ETA:  --:--:--\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m mean_rewards \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(episode):\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# collect trajectories\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     old_probs, states, actions, rewards \u001b[38;5;241m=\u001b[39m \u001b[43mpong_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmax\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     total_rewards \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(rewards, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# gradient ascent step\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Repositories\\deep-reinforcement-learning\\pong-PPO-REINFORCE\\pong_utils.py:107\u001b[0m, in \u001b[0;36mcollect_trajectories\u001b[1;34m(envs, policy, tmax, nrand)\u001b[0m\n\u001b[0;32m    104\u001b[0m prob_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m    105\u001b[0m action_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m--> 107\u001b[0m \u001b[43menvs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# start all parallel agents\u001b[39;00m\n\u001b[0;32m    110\u001b[0m envs\u001b[38;5;241m.\u001b[39mstep([\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mn)\n",
      "File \u001b[1;32m~\\Documents\\Repositories\\deep-reinforcement-learning\\pong-PPO-REINFORCE\\parallelEnv.py:170\u001b[0m, in \u001b[0;36mparallelEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m remote \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremotes:\n\u001b[0;32m    169\u001b[0m     remote\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremotes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\general\\lib\\site-packages\\numpy\\core\\shape_base.py:458\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mARRAY_FUNCTION_ENABLED:\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# raise warning if necessary\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     _arrays_for_stack_dispatcher(arrays, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [asanyarray(arr) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\general\\lib\\site-packages\\numpy\\core\\shape_base.py:458\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mARRAY_FUNCTION_ENABLED:\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# raise warning if necessary\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     _arrays_for_stack_dispatcher(arrays, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m arrays:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneed at least one array to stack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "\n",
    "#import numpy as np\n",
    "# keep track of how long training takes\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "\n",
    "# training loop max iterations\n",
    "episode = 400\n",
    "\n",
    "# widget bar to display progress\n",
    "#!pip install progressbar\n",
    "#import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "epsilon = 0.1\n",
    "beta = .01\n",
    "tmax = 320\n",
    "SGD_epoch = 4\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "    # gradient ascent step\n",
    "    for _ in range(SGD_epoch):\n",
    "        \n",
    "        # uncomment to utilize your own clipped function!\n",
    "        L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "        #L = -pong_utils.clipped_surrogate(policy, old_probs, states, actions, rewards,\n",
    "        #                                  epsilon=epsilon, beta=beta)\n",
    "        optimizer.zero_grad()\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        del L\n",
    "    \n",
    "    # the clipping parameter reduces as time goes on\n",
    "    epsilon*=.999\n",
    "    \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 == 0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1, np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgEbiI-w2qku"
   },
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fWqGYjg2qku"
   },
   "outputs": [],
   "source": [
    "# save your policy!\n",
    "#torch.save(policy, 'pong_PPO.policy')\n",
    "\n",
    "# load policy if needed\n",
    "# policy = torch.load('PPO.policy')\n",
    "\n",
    "# try and test out the solution \n",
    "# make sure GPU is enabled, otherwise loading will fail\n",
    "# (the PPO verion can win more often than not)!\n",
    "#\n",
    "if device != 'cpu':\n",
    "    policy_solution = torch.load('data/PPO_OG.policy')\n",
    "    pong_utils.play(env, policy_solution, time=2000) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
