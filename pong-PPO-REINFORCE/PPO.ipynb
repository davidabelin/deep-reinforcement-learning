{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.0\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in c:\\users\\david\\.conda\\envs\\drlnd\\lib\\site-packages (0.1)\n",
      "using device:  cpu\n"
     ]
    }
   ],
   "source": [
    "# install package for displaying animation\n",
    "!pip install JSAnimation\n",
    "\n",
    "# custom utilies for displaying animation, collecting rollouts and more\n",
    "import pong_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check which device is being used. \n",
    "# I recommend disabling gpu until you've made sure that the code runs\n",
    "device = pong_utils.device\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ba93f0fec10b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-ba93f0fec10b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import gym[atari]\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "import gym\n",
    "import time\n",
    "\n",
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show what a preprocessed image looks like\n",
    "env.reset()\n",
    "_, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _ = env.step(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def output_volume(in_dims, k=3, s=2, p=0, transpose=False):\n",
    "    ''' Calculate a convolutional layer's output size params:\n",
    "        in_dims = input size (int)\n",
    "        k = kernel size \n",
    "        s = stride (int)\n",
    "        p = padding (int)\n",
    "    '''\n",
    "    if not transpose:\n",
    "        out_size = (in_dims - k + 2*p)/s + 1 #convolution out\n",
    "    else:\n",
    "        out_size = (in_dims - 1)*s + k - 2*p #deconvolution out\n",
    "    return int(np.floor(out_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 784, 12800, 112.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_volume(26, 6, 3, 0), 7*7*16, 80*80*2, 784/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "                        #self.batchnorm = nn.BatchNorm2d()\n",
    "        # 2 channel from the stacked frame\n",
    "        # 80x80x2 to 26x26x8\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=5, stride=3, padding=1, bias=False)\n",
    "        # 26x26x8 to 7x7x16\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=6, stride=3)\n",
    "        self.size=7*7*16  #=784\n",
    "        \n",
    "        # two fully connected layer\n",
    "        self.fc1 = nn.Linear(self.size, 112) # =7*16\n",
    "        self.fc2 = nn.Linear(112, 1)\n",
    "\n",
    "        # Sigmoid to \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1,self.size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.sig(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run your own policy!\n",
    "policy=Policy().to(device)\n",
    "\n",
    " # Solution policy:\n",
    "#policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) \n",
    "\n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "## Exercise 2: write your own function for training\n",
    "(what I call scalar function is the same as policy_loss up to a negative sign)\n",
    "\n",
    "### PPO\n",
    "Later on, you'll implement the PPO algorithm as well, and the scalar function is given by\n",
    "$\\frac{1}{T}\\sum^T_t \\min\\left\\{R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)},R_{t}^{\\rm future}{\\rm clip}_{\\epsilon}\\!\\left(\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}\\right)\\right\\}$\n",
    "\n",
    "the ${\\rm clip}_\\epsilon$ function is implemented in pytorch as ```torch.clamp(ratio, 1-epsilon, 1+epsilon)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount=0.99\n",
    "rewards=np.random.rand(64)\n",
    "discount = discount**np.arange(64)\n",
    "discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards#.shape# = np.asarray(rewards)*discount[:,np.newaxis]\n",
    "#discount[:,np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewards_future = rewards[::-1].cumsum(axis=0)[::-1]\n",
    "#rewards_future.shape\n",
    "rewards[::-1].cumsum(axis=0).shape#[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_surrogate(policy, old_probs, states, actions, rewards, discount = 0.995, epsilon=0.1, beta=0.01):\n",
    "    ## WRITE YOUR OWN CODE HERE  ## from plot_utils\n",
    "    #####################?\n",
    "    discount = discount**np.arange(len(rewards))\n",
    "    rewards = np.asarray(rewards)*discount[:,np.newaxis]\n",
    "    \n",
    "    # convert rewards to future rewards\n",
    "    rewards_future = rewards[::-1].cumsum(axis=0)[::-1]\n",
    "    \n",
    "    mean = np.mean(rewards_future, axis=1)\n",
    "    std = np.std(rewards_future, axis=1) + 1.0e-10\n",
    "\n",
    "    rewards_normalized = (rewards_future - mean[:,np.newaxis])/std[:,np.newaxis]\n",
    "    ######################?\n",
    "    \n",
    "    # move to gpu if available\n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float, device=device)\n",
    "    rewards = torch.tensor(rewards_normalized, dtype=torch.float, device=device)\n",
    "\n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = pong_utils.states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "\n",
    "    # ratio for clipping\n",
    "    ratio = new_probs/old_probs\n",
    "\n",
    "    # clipped function\n",
    "    clip = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "    clipped_surrogate = torch.min(ratio*rewards, clip*rewards)\n",
    "    \n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # prevents policy to become exactly 0 or 1 helps exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    entropy = -(new_probs*torch.log(old_probs+1.e-10)+(1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "\n",
    "    # this returns an average of all the entries of the tensor\n",
    "    # effective computing L_sur^clip / T\n",
    "    # averaged over time-step and number of trajectories\n",
    "    # this is desirable because we have normalized our rewards\n",
    "    return torch.mean(clipped_surrogate + beta*entropy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting progressbar\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
      "Building wheels for collected packages: progressbar\n",
      "  Running setup.py bdist_wheel for progressbar ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "\n",
    "# widget bar to display progress\n",
    "!pip install progressbar\n",
    "import progressbar as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-41:\n",
      "Process Process-44:\n",
      "Process Process-40:\n",
      "Process Process-42:\n",
      "Process Process-39:\n",
      "Process Process-34:\n",
      "Process Process-37:\n",
      "Process Process-35:\n",
      "Process Process-33:\n",
      "Process Process-36:\n",
      "Process Process-38:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-43:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/workspace/parallelEnv.py\", line 104, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "envs = parallelEnv('PongDeterministic-v4', n=12, seed=1234)\n",
    "\n",
    "discount_rate = .992  #\n",
    "epsilon = 0.1  #\n",
    "beta = .01     #\n",
    "tmax = 1000    # training loop max = ? \n",
    "SGD_epoch = 8  #\n",
    "\n",
    "# episodes = number episode batches to collect?\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "episodes = 20  #800\n",
    "\n",
    "def train(policy, envs, episodes, tmax, SGD_epoch, gamma=discount_rate, epsilon=epsilon, beta=beta):\n",
    "\n",
    "    # keep track of progress\n",
    "    mean_rewards = []\n",
    "\n",
    "    # keep track of how long training takes\n",
    "    widget = ['training loop: ', pb.Percentage(), ' ', pb.Bar(), ' ', pb.ETA() ]\n",
    "    timer = pb.ProgressBar(widgets=widget, maxval=episodes).start()\n",
    "\n",
    "    for e in range(episodes):\n",
    "\n",
    "        # collect trajectories\n",
    "        old_probs, states, actions, rewards = pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "\n",
    "        total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "        # gradient ascent step\n",
    "        for _ in range(SGD_epoch):\n",
    "\n",
    "            # uncomment to utilize your own clipped function!\n",
    "            L = -clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "\n",
    "            #L = -pong_utils.clipped_surrogate(policy, old_probs, states, actions, rewards, epsilon=epsilon, beta=beta)\n",
    "            optimizer.zero_grad()\n",
    "            L.backward()\n",
    "            optimizer.step()\n",
    "            del L\n",
    "\n",
    "        # the clipping parameter reduces as time goes on\n",
    "        epsilon*=.999\n",
    "\n",
    "        # the regulation term also reduces\n",
    "        # this reduces exploration in later runs\n",
    "        beta*=.995\n",
    "\n",
    "        # get the average reward of the parallel environments\n",
    "        mean_rewards.append(np.mean(total_rewards))\n",
    "\n",
    "        # display some progress every 20 iterations\n",
    "        if (e+1)%20 ==0 :\n",
    "            print(\"Episode: {0:d}, Avg. score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "            print(total_rewards)\n",
    "\n",
    "        # update progress widget bar\n",
    "        timer.update(e+1)\n",
    "\n",
    "    timer.finish()\n",
    "    return mean_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  20% |########                                   | ETA:  0:18:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 20, Avg. score: -17.562500\n",
      "[-19. -16. -19. -16. -16. -16. -20. -17. -17. -20. -20. -17. -17. -20. -17.\n",
      " -14.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  40% |#################                          | ETA:  0:13:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 40, Avg. score: -16.250000\n",
      "[-16. -19. -17. -18. -19. -18. -14. -18. -18. -20. -19. -12. -10. -14. -13.\n",
      " -15.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  60% |#########################                  | ETA:  0:08:39\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 60, Avg. score: -13.875000\n",
      "[-14. -12. -18. -13. -12. -12. -15. -16. -12. -14. -12. -12. -14. -14. -16.\n",
      " -16.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  80% |##################################         | ETA:  0:04:18\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 80, Avg. score: -10.000000\n",
      "[ -9. -10. -13.  -6. -14.  -6.  -8. -10. -10. -10.  -6. -10. -13. -14.  -7.\n",
      " -14.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop: 100% |###########################################| Time: 0:21:30\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, Avg. score: -6.687500\n",
      "[-13.  -7.  -9.  -8.  -9.  -5.  -2.  -5.  -3.  -2.  -9.  -7.  -5.  -9.  -4.\n",
      " -10.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Control \n",
    "#envs = parallelEnv('PongDeterministic-v4', n=16, seed=1234)\n",
    "discount_rate = .99  #\n",
    "epsilon = 0.075  #\n",
    "beta = .01     #\n",
    "tmax = 800    # 1000 training loop max = ? \n",
    "SGD_epoch = 4  #\n",
    "episodes = 100  #800\n",
    "\n",
    "mean_rewards += train(policy, envs, episodes, tmax, SGD_epoch, gamma=discount_rate, epsilon=epsilon, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rewards = train(policy, envs, episodes, tmax, SGD_epoch, gamma=discount_rate, epsilon=epsilon, beta=beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f02d6a3ee80>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02d41ef470>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mean_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pong_utils.play(env, policy, time=200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Policy. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# save your policy!\n",
    "torch.save(policy, 'PPO_X.policy')\n",
    "\n",
    "# load policy if needed\n",
    "#policy = torch.load('PPO.policy')\n",
    "#pong_utils.play(env, policy, time=1000) \n",
    "\n",
    "# try and test out the solution \n",
    "# make sure GPU is enabled, otherwise loading will fail\n",
    "# (the PPO verion can win more often than not)!\n",
    "#\n",
    "#policy_solution = torch.load('PPO_solution.policy')\n",
    "#pong_utils.play(env, policy_solution, time=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
